train:
  experiment_name: 'semantic_sam'

  # Model
  model:
    sam_name: 'sem_sam'
    params:
      # Fix the a part of parameters in SAM
      fix_img_en: True
      fix_prompt_en: True
      fix_mask_de: False
      ckpt_path: '/content/sam_vit_b.pth'
      class_num: 4 # 0,1,2,4
      model_type: 'vit_b'    # type should be in [vit_h, vit_b, vit_l, default]

  losses:
    DiceCE

  
  # Optimizer
  opt_params:
#    lr_default: 5e-6 # 1e-3
    lr_default:  1e-4
    wd_default: 1e-4
    # momentum: 0.9
    lr_list:  [ 1e-2, ]
#    lr_list: [5e-6, ] # [ 1e-2, ]

    group_keys: [ [ 'mask_adapter.decoder_head.output_hypernetworks_mlps', ], ]
    wd_list:  [ 0.0 ]
#    wd_list: [1e-4] # [ 0.0 ]
  
  scheduler_name: 'cosine'
  opt_name: 'adamw' # 'sgd'
  
  # Logger
  use_tensorboard: True
  tensorboard_folder: './experiment/tensorboard'
  log_folder: './experiment/log'
  model_folder: './experiment/model'
  
  # Others
  max_iter: 10000 # look into
  log_iter: 20
  eval_iter: 200
  runner_name: 'sem_runner'
  bs: 8 # 8
  num_workers: 2
  drop_last: True